{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a6071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from math import pi\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5d8b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "# Define the exact solution\n",
    "def exact_solution(x, t):\n",
    "    return torch.sin(x)*torch.cos(pi*t)\n",
    "\n",
    "def initial_condition(x):\n",
    "    return torch.sin(x)\n",
    "\n",
    "def initial_condition_t(x):\n",
    "    return 0*torch.cos(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d9104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning number of points\n",
    "initial_pts = 500\n",
    "left_boundary_pts = 500\n",
    "right_boundary_pts = 500\n",
    "residual_pts = 10000\n",
    "\n",
    "# Type of optimizer (ADAM or LBFGS)\n",
    "opt_type = \"LBFGS\"\n",
    "\n",
    "x_init = 8*pi*torch.rand((initial_pts,1)) # initial pts\n",
    "t_init = 0*x_init\n",
    "init = torch.cat([x_init, t_init],1).to(device)\n",
    "u_init = initial_condition(init[:,0]).reshape(-1, 1)\n",
    "u_init_t = 0*initial_condition(init[:,0]).reshape(-1, 1)\n",
    "\n",
    "xb_left = torch.zeros((left_boundary_pts, 1)) # left spatial boundary\n",
    "tb_left = torch.rand((left_boundary_pts, 1)) #\n",
    "b_left = torch.cat([xb_left, tb_left ],1).to(device)\n",
    "u_b_l = 0*torch.sin(tb_left)\n",
    "\n",
    "xb_right = 8*pi*torch.ones((right_boundary_pts, 1)) # right spatial boundary\n",
    "tb_right = torch.rand((right_boundary_pts, 1)) # right boundary pts\n",
    "b_right = torch.cat([xb_right, tb_right ],1).to(device)\n",
    "u_b_r = 0*torch.sin(2*pi - tb_right)\n",
    "\n",
    "x_interior = 8*pi*torch.rand((residual_pts, 1))\n",
    "t_interior = torch.rand((residual_pts, 1))\n",
    "interior = torch.cat([x_interior, t_interior],1).to(device)\n",
    "\n",
    "training_set = DataLoader(torch.utils.data.TensorDataset(init.to(device), u_init.to(device), u_init_t.to(device), b_left.to(device),  b_right.to(device), u_b_l.to(device), u_b_r.to(device)), batch_size=500, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5f5744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NeuralNet(nn.Module):\n",
    "\n",
    "#     def __init__(self, input_dimension, output_dimension, n_hidden_layers, neurons):\n",
    "#         super(NeuralNet, self).__init__()\n",
    "#         # Number of input dimensions n\n",
    "#         self.input_dimension = input_dimension\n",
    "#         # Number of output dimensions m\n",
    "#         self.output_dimension = output_dimension\n",
    "#         # Number of neurons per layer\n",
    "#         self.neurons = neurons\n",
    "#         # Number of hidden layers\n",
    "#         self.n_hidden_layers = n_hidden_layers\n",
    "#         # Activation function\n",
    "#         self.activation = nn.Tanh()\n",
    "\n",
    "#         self.input_layer = nn.Linear(self.input_dimension, self.neurons)\n",
    "#         self.hidden_layers = nn.ModuleList([nn.Linear(self.neurons, self.neurons) for _ in range(n_hidden_layers)])\n",
    "#         self.output_layer = nn.Linear(self.neurons, self.output_dimension)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # The forward function performs the set of affine and non-linear transformations defining the network\n",
    "#         # (see equation above)\n",
    "#         x = self.activation(self.input_layer(x))\n",
    "#         for k, l in enumerate(self.hidden_layers):\n",
    "#             x = self.activation(l(x))\n",
    "#         return self.output_layer(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96097d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dimension, output_dimension, n_hidden_layers, neurons):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        # Number of input dimensions n\n",
    "        self.input_dimension = input_dimension\n",
    "        # Number of output dimensions m\n",
    "        self.output_dimension = output_dimension\n",
    "        # Number of neurons per layer\n",
    "        self.neurons = neurons\n",
    "        # Number of hidden layers\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "\n",
    "        # Trainable parameter for the activation function\n",
    "        self.a = nn.Parameter(torch.randn(1))\n",
    "\n",
    "        self.input_layer = nn.Linear(self.input_dimension, self.neurons)\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(self.neurons, self.neurons) for _ in range(n_hidden_layers)])\n",
    "        self.output_layer = nn.Linear(self.neurons, self.output_dimension)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # The forward function performs the set of affine and non-linear transformations defining the network\n",
    "        # (see equation above)\n",
    "        x = self.a * torch.tanh(self.input_layer(x))\n",
    "        for k, l in enumerate(self.hidden_layers):\n",
    "            x = self.a * torch.tanh(l(x))\n",
    "        return self.output_layer(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73441b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "my_network = NeuralNet(input_dimension = init.shape[1], output_dimension = u_init.shape[1], n_hidden_layers=4, neurons=200)\n",
    "my_network = my_network.to(device)\n",
    "\n",
    "def init_xavier(model, retrain_seed):\n",
    "    torch.manual_seed(retrain_seed)\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear and m.weight.requires_grad and m.bias.requires_grad:\n",
    "            g = nn.init.calculate_gain('tanh')\n",
    "            torch.nn.init.xavier_uniform_(m.weight, gain=g)\n",
    "            #torch.nn.init.xavier_normal_(m.weight, gain=g)\n",
    "            m.bias.data.fill_(0)\n",
    "    model.apply(init_weights)\n",
    "\n",
    "# Random Seed for weight initialization\n",
    "retrain = 128\n",
    "# Xavier weight initialization\n",
    "init_xavier(my_network, retrain)\n",
    "\n",
    "if opt_type == \"ADAM\":\n",
    "    optimizer_ = optim.Adam(my_network.parameters(), lr=0.001)\n",
    "elif opt_type == \"LBFGS\":\n",
    "    optimizer_ = optim.LBFGS(my_network.parameters(), lr=0.1, max_iter=1, max_eval=50000, tolerance_change=1.0 * np.finfo(float).eps)\n",
    "else:\n",
    "    raise ValueError(\"Optimizer not recognized\")\n",
    "\n",
    "\n",
    "def fit(model, training_set, interior, num_epochs, optimizer, p, verbose=True):\n",
    "    history = list()\n",
    "\n",
    "    # Loop over epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        if verbose: print(\"################################ \", epoch, \" ################################\")\n",
    "\n",
    "        running_loss = list([0])\n",
    "\n",
    "        # Loop over batches\n",
    "        for j, (initial, u_initial, u_initial_t, bd_left, bd_right, ubl, ubr) in enumerate(training_set):\n",
    "            def closure():\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # for initial\n",
    "                initial.requires_grad = True\n",
    "                u_initial_pred_ = model(initial)\n",
    "                inputs = torch.ones(initial_pts, 1).to(device)\n",
    "                grad_u_init = torch.autograd.grad(u_initial_pred_, initial, grad_outputs=inputs, create_graph=True)[0]\n",
    "                u_init_t = grad_u_init[:, 1].reshape(-1, )\n",
    "\n",
    "                # for left boundary\n",
    "                bd_left.requires_grad = True\n",
    "                bd_left_pred_ = model(bd_left)\n",
    "                inputs = torch.ones(left_boundary_pts, 1).to(device)\n",
    "                grad_bd_left = torch.autograd.grad(bd_left_pred_, bd_left, grad_outputs=inputs, create_graph=True)[0]\n",
    "                u_bd_x_left = grad_bd_left[:, 0].reshape(-1, )\n",
    "                inputs = torch.ones(left_boundary_pts, 1).reshape(-1, ).to(device)\n",
    "                grad_u_bd_x_left = torch.autograd.grad(u_bd_x_left, bd_left, grad_outputs=inputs, create_graph=True)[0]\n",
    "                u_bd_xx_left = grad_u_bd_x_left[:, 0].reshape(-1, )\n",
    "                inputs = torch.ones(left_boundary_pts, 1).reshape(-1, ).to(device)\n",
    "                grad_u_bd_xx_left = torch.autograd.grad(u_bd_xx_left, bd_left, grad_outputs=inputs, create_graph=True)[0]\n",
    "                u_bd_xxx_left = grad_u_bd_xx_left[:, 0].reshape(-1, )\n",
    "\n",
    "                # for right boundary\n",
    "                bd_right.requires_grad = True\n",
    "                bd_right_pred_ = model(bd_right)\n",
    "                inputs = torch.ones(right_boundary_pts, 1).to(device)\n",
    "                grad_bd_right = torch.autograd.grad(bd_right_pred_, bd_right, grad_outputs=inputs, create_graph=True)[0]\n",
    "                u_bd_x_right = grad_bd_right[:, 0].reshape(-1, )\n",
    "                inputs = torch.ones(right_boundary_pts, 1).reshape(-1, ).to(device)\n",
    "                grad_u_bd_x_right = torch.autograd.grad(u_bd_x_right, bd_right, grad_outputs=inputs, create_graph=True)[0]\n",
    "                u_bd_xx_right = grad_u_bd_x_right[:, 0].reshape(-1, )\n",
    "\n",
    "                # residual calculation\n",
    "                interior.requires_grad = True\n",
    "                u_hat = model(interior)\n",
    "                inputs = torch.ones(residual_pts, 1).to(device)\n",
    "                grad_u_hat = torch.autograd.grad(u_hat, interior, grad_outputs=inputs, create_graph=True)[0]\n",
    "\n",
    "                u_x = grad_u_hat[:, 0].reshape(-1, )\n",
    "                inputs = torch.ones(residual_pts, 1).reshape(-1, ).to(device)\n",
    "                grad_u_x = torch.autograd.grad(u_x, interior, grad_outputs=inputs, create_graph=True)[0]\n",
    "                u_xx = grad_u_x[:, 0].reshape(-1, )\n",
    "                inputs = torch.ones(residual_pts, 1).reshape(-1, ).to(device)\n",
    "                grad_u_xx = torch.autograd.grad(u_xx, interior, grad_outputs=inputs, create_graph=True)[0]\n",
    "                u_xxx = grad_u_xx[:, 0].reshape(-1, )\n",
    "                inputs = torch.ones(residual_pts, 1).reshape(-1, ).to(device)\n",
    "                grad_u_xxx = torch.autograd.grad(u_xxx, interior, grad_outputs=inputs, create_graph=True)[0]\n",
    "                u_xxxx = grad_u_xxx[:, 0].reshape(-1, )\n",
    "\n",
    "                u_t = grad_u_hat[:, 1]\n",
    "                inputs = torch.ones(residual_pts, 1).reshape(-1, ).to(device)\n",
    "                grad_u_t = torch.autograd.grad(u_t, interior, grad_outputs=inputs, create_graph=True)[0]\n",
    "                u_tt = grad_u_t[:, 1].reshape(-1, )\n",
    "\n",
    "                # Item 1. below\n",
    "\n",
    "                loss_ic = torch.mean((u_initial_pred_.reshape(-1, ) - u_initial.reshape(-1, )) ** p) + \\\n",
    "                          torch.mean((u_init_t.reshape(-1, )) ** p)\n",
    "                loss_pde = torch.mean((u_tt.reshape(-1, ) + u_xxxx.reshape(-1, ) - (2-pi**2)*torch.sin(interior[:,0])*torch.cos(pi*interior[:,1])) ** p)\n",
    "                loss_left_b = torch.mean((u_bd_x_left.reshape(-1, ) - ubl.reshape(-1, )) ** p) + \\\n",
    "                              torch.mean((u_bd_xx_left.reshape(-1, ) - ubl.reshape(-1, )) ** p)\n",
    "                loss_right_b = torch.mean((bd_right_pred_.reshape(-1, ) - ubr.reshape(-1, )) ** p) + \\\n",
    "                               torch.mean((u_bd_xx_right.reshape(-1, ) - ubr.reshape(-1, )) ** p)\n",
    "\n",
    "                loss = loss_ic + loss_pde + loss_left_b + loss_right_b\n",
    "\n",
    "                # Item 2. below\n",
    "                loss.backward()\n",
    "                # Compute average training loss over batches for the current epoch\n",
    "                running_loss[0] += loss.item()\n",
    "                return loss\n",
    "\n",
    "            # Item 3. below\n",
    "            optimizer.step(closure=closure)\n",
    "\n",
    "        print('Loss: ', (running_loss[0] / len(training_set)))\n",
    "        history.append(running_loss[0])\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a242aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10000\n",
    "start_time = time.time()\n",
    "history = fit(my_network, training_set, interior, n_epochs, optimizer_, p=2, verbose=True )\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(\"Training time: {:.2f} seconds\".format(total_time))\n",
    "\n",
    "\n",
    "with open('PINN_EB_adaptive.pkl', 'wb') as f:\n",
    "    pickle.dump(history, f)\n",
    "\n",
    "f.close()\n",
    "\n",
    "model_state_dict = my_network.state_dict()\n",
    "\n",
    "# Save the model state dictionary to a file\n",
    "torch.save(model_state_dict, 'PINN_EB_adaptive.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77a87c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # loading model\n",
    "\n",
    "# # Load the history from the pickle file\n",
    "# with open('PINN_EB_adaptive.pkl', 'rb') as f:\n",
    "#     history = pickle.load(f)\n",
    "\n",
    "# # # Load the model architecture\n",
    "# # my_network = your_model_module.YourModelClass()  # Instantiate your model class\n",
    "\n",
    "# # Load the saved model state dictionary\n",
    "# model_state_dict = torch.load('PINN_EB_adaptive.pth',  map_location=torch.device('cpu'))\n",
    "\n",
    "# # Load the model weights\n",
    "# my_network.load_state_dict(model_state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf054d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.linspace(0, 8*pi, 10000).reshape(-1,1)\n",
    "t_test = torch.ones((10000,1))\n",
    "test = torch.cat([x_test, t_test],1)\n",
    "u_test = exact_solution(x_test, t_test).reshape(-1,1)\n",
    "my_network = my_network.cpu()\n",
    "u_test_pred = my_network(test).reshape(-1,1)\n",
    "\n",
    "# Compute the relative L2 error norm (generalization error)\n",
    "relative_error_test = torch.mean((u_test_pred - u_test)**2)/torch.mean(u_test**2)\n",
    "print(\"Relative Error Test: \", relative_error_test.detach().numpy()*100, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c935f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = 8*pi*torch.rand(100000).reshape(-1,1)\n",
    "t_test = torch.rand(100000).reshape(-1,1)\n",
    "test = torch.cat([x_test, t_test],1)\n",
    "u_test = exact_solution(x_test,t_test).reshape(-1,1)\n",
    "u_test_pred = my_network(test).reshape(-1,1)\n",
    "relative_error = torch.abs(u_test_pred - u_test)\n",
    "u_test = u_test.reshape(-1,)\n",
    "\n",
    "# reshaping and detach numpy\n",
    "x_test = x_test.reshape(-1, )\n",
    "t_test = t_test.reshape(-1, )\n",
    "relative_error = relative_error.reshape(-1,)\n",
    "u_test_pred = u_test_pred.reshape(-1, )\n",
    "\n",
    "x_test = x_test.detach().numpy()\n",
    "t_test = t_test.detach().numpy()\n",
    "u_test_pred = u_test_pred.detach().numpy()\n",
    "relative_error = relative_error.detach().numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 4]\n",
    "\n",
    "from matplotlib.font_manager import FontProperties\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "font_path = 'times-new-roman.ttf'\n",
    "\n",
    "custom_font = FontProperties(fname=font_path)\n",
    "\n",
    "\n",
    "        \n",
    "CS1 = plt.tricontourf(x_test, t_test, u_test_pred, 20, cmap='rainbow')\n",
    "#CS1 = plt.tricontourf(x_test, t_test, u_test, 20, cmap='rainbow')\n",
    "#CS1 = plt.tricontourf(x_test, t_test, relative_error, 20, cmap='rainbow')\n",
    "\n",
    "\n",
    "\n",
    "cbar1 = plt.colorbar(CS1)\n",
    "for t in cbar1.ax.get_yticklabels():\n",
    "    t.set_fontproperties(custom_font)\n",
    "    t.set_fontsize(20)\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('x', fontsize=20, fontproperties=custom_font)\n",
    "plt.ylabel('t', fontsize=20, fontproperties=custom_font)\n",
    "plt.xticks(fontsize=20, fontproperties=custom_font)\n",
    "plt.yticks(fontsize=20, fontproperties=custom_font)\n",
    "plt.savefig('PINN_EB.pdf', dpi = 300, bbox_inches = \"tight\")\n",
    "#plt.savefig('Exact_EB.pdf', dpi = 300, bbox_inches = \"tight\")\n",
    "#plt.savefig('Absolute_error_EB.pdf', dpi = 300, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407f519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "# Assuming you have imported your data and defined necessary functions\n",
    "\n",
    "# Rest of your code...\n",
    "\n",
    "# # Convert the font size to points\n",
    "font_size = 20\n",
    "# ticks_font = FontProperties(family='Times New Roman', style='normal', size=font_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_test = 8*pi*torch.rand(100000).reshape(-1,1)\n",
    "t_test = torch.rand(100000).reshape(-1,1)\n",
    "test = torch.cat([x_test, t_test],1)\n",
    "u_test = exact_solution(x_test,t_test).reshape(-1,1)\n",
    "u_test_pred = my_network(test).reshape(-1,1)\n",
    "relative_error = torch.abs(u_test_pred - u_test)\n",
    "u_test = u_test.reshape(-1,)\n",
    "\n",
    "# reshaping and detach numpy\n",
    "x_test = x_test.reshape(-1, )\n",
    "t_test = t_test.reshape(-1, )\n",
    "relative_error = relative_error.reshape(-1,)\n",
    "u_test_pred = u_test_pred.reshape(-1, )\n",
    "\n",
    "x_test = x_test.detach().numpy()\n",
    "t_test = t_test.detach().numpy()\n",
    "u_test_pred = u_test_pred.detach().numpy()\n",
    "relative_error = relative_error.detach().numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 4]\n",
    "\n",
    "from matplotlib.font_manager import FontProperties\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "font_path = 'times-new-roman.ttf'\n",
    "\n",
    "ticks_font = FontProperties(fname=font_path)\n",
    "\n",
    "# Define the levels for contouring\n",
    "levels = np.linspace(-1.5, 1.5, 20)\n",
    "\n",
    "        \n",
    "CS1 = plt.tricontourf(x_test, t_test, u_test_pred, levels, cmap='twilight')\n",
    "#CS1 = plt.tricontourf(x_test, t_test, u_test, 20, cmap='twilight')\n",
    "#CS1 = plt.tricontourf(x_test, t_test, relative_error, 20, cmap='rainbow')\n",
    "\n",
    "\n",
    "\n",
    "#cbar1 = plt.colorbar(CS1)\n",
    "for t in cbar1.ax.get_yticklabels():\n",
    "    t.set_fontproperties(custom_font)\n",
    "    t.set_fontsize(20)\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('x', fontsize=20, fontproperties=custom_font)\n",
    "plt.ylabel('t', fontsize=20, fontproperties=custom_font)\n",
    "plt.xticks(fontsize=20, fontproperties=custom_font)\n",
    "plt.yticks(fontsize=20, fontproperties=custom_font)\n",
    "#plt.savefig('Causal_EB.pdf', dpi = 300, bbox_inches = \"tight\")\n",
    "plt.savefig('PINN_EB.pdf', dpi=500, bbox_inches=\"tight\", format='pdf', backend='cairo')\n",
    "#plt.savefig('Absolute_error_EB.pdf', dpi = 300, bbox_inches = \"tight\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f01ae3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
